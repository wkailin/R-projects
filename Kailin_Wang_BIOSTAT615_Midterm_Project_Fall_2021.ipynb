{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiAtZF-dHHBz"
   },
   "source": [
    "# BIOSTAT615 Midterm Project - Fall 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29hcNSQSXKhU"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This midterm project aims to implement open-ended methods to <u>***classify*** </u> and <u>***cluster***</u> widely known hand-written digit database, called MNIST database. \n",
    "\n",
    "This document describes how you can read MNIST dataset in R, how you can perfom simple classification tasks, and described how you can implement your own classification and clustering tasks. \n",
    "\n",
    "To complete your midterm project, you will need to take the following steps:\n",
    "1. Copy this document for your own version for editing\n",
    "2. Rename the document title to start with your own name: for example \"John Doe - BIOSTAT615 Midterm Project - Fall 2021\".\n",
    "3. Read this document carefully to understand what are required and recommended tasks\n",
    "4. Complete the required (and optional) tasks\n",
    "5. Write your own report in your copy of notebook directly\n",
    "6. Share your copy of the notebook with instructors (hmkang@umich.edu , ylzhong@umich.edu) as viewers (make sure that you do not share it with anyone else), and submit the URL to the notebook in Canvas.\n",
    "\n",
    "You should be able to use Markdown language to write your own report. See [Markdown Guide](https://colab.research.google.com/notebooks/markdown_guide.ipynb) to learn how to modify your copy of this report using Markdown. You may also want to read [LaTeX Tutorial](https://en.wikibooks.org/wiki/LaTeX/Mathematics) to learn how to write mathematical equations in your report (or you can import equations as external images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNMPLzUBXG8w"
   },
   "source": [
    "## Background\n",
    "\n",
    "This section introduces what the MNIST dataset looks like, and explains how you can use them for your project.\n",
    "\n",
    "### Preambles\n",
    "\n",
    "First, let's try to load some R packages we will use for some of the example exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MW9cajZgxcPr",
    "outputId": "0a8eddd1-a907-4e2b-81c7-99b39c357951"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "Loaded glmnet 4.1-3\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# install.packages(\"glmnet\") ## glmnet will be used as a example classification\n",
    "# install.packages(\"tictoc\") ## tictoc will be used for evaluating time\n",
    "library(ggplot2)\n",
    "library(glmnet)\n",
    "library(tictoc)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3tym2Lcq5v-"
   },
   "source": [
    "### Loading MNIST dataset\n",
    "\n",
    "[MNIST](http://yann.lecun.com/exdb/mnist/) is a widely recognized databases of handwritten digits, containing thousands of labeled images in a standardized form. This data has been one of the gold-standard dataset to evaluate various machine learning methods. In this project, we will NOT require implement any machine learning or deep learning methods, but will use these data as an easy-to-visualize high-dimensional data. \n",
    "\n",
    "The code fragment below will load train (n=60,000) and test (n=10,000) images and labels (0 to 9), and visualize the images to improve your understanding. First, we will download these data from the web "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3vEZcgrKcRLX"
   },
   "outputs": [],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## set up the location of MNIST files\n",
    "baseUrl = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "trainXf = \"train-images-idx3-ubyte.gz\"  ## train images\n",
    "trainYf = \"train-labels-idx1-ubyte.gz\"  ## train labels\n",
    "testXf = \"t10k-images-idx3-ubyte.gz\"    ## test images\n",
    "testYf = \"t10k-labels-idx1-ubyte.gz\"    ## test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tpYRV0FHdPkm"
   },
   "outputs": [],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## Download MNIST data\n",
    "filenames = c(trainXf, trainYf, testXf, testYf)\n",
    "for(fn in filenames) { \n",
    "  if ( !file.exists(fn) ) { ## skip download if already exists\n",
    "    system(paste0(\"wget \",baseUrl, fn),intern=TRUE)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pl_BpFBrfWvy",
    "outputId": "500a4867-f4d5-4744-971e-bda7d76f4fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"total 24088\"                                                                                            \n",
      " [2] \"-rw-r--r--  1 kailin  staff   120342 11 23 02:24 11.23_v1\"                                              \n",
      " [3] \"-rw-r--r--  1 kailin  staff    86884 11 22 23:13 1122.ipynb\"                                            \n",
      " [4] \"-rw-r--r--  1 kailin  staff    87945 11 22 23:11 1a_done.ipynb\"                                         \n",
      " [5] \"-rw-r--r--  1 kailin  staff   106042 11 19 18:30 2a_done.ipynb\"                                         \n",
      " [6] \"-rw-r--r--@ 1 kailin  staff   120342 11 23 02:24 Kailin_Wang_BIOSTAT615_Midterm_Project_Fall_2021.ipynb\"\n",
      " [7] \"-rw-r--r--@ 1 kailin  staff  1648877 11 12 19:31 t10k-images-idx3-ubyte.gz\"                             \n",
      " [8] \"-rw-r--r--@ 1 kailin  staff     4542 11 12 19:32 t10k-labels-idx1-ubyte.gz\"                             \n",
      " [9] \"-rw-r--r--@ 1 kailin  staff  9912422 11 12 19:31 train-images-idx3-ubyte.gz\"                            \n",
      "[10] \"-rw-r--r--@ 1 kailin  staff    28881 11 12 19:31 train-labels-idx1-ubyte.gz\"                            \n",
      "[11] \"-rw-r--r--  1 kailin  staff    93558 11 16 12:21 version1.ipynb\"                                        \n",
      "[12] \"-rw-r--r--  1 kailin  staff    97805 11 13 23:27 version2.ipynb\"                                        \n"
     ]
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## verify the downloaded files\n",
    "print(system(\"ls -l\",intern=TRUE))\n",
    "## Below is what you are expected to see when run this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXRucF9Pfq0U"
   },
   "source": [
    "The download data is a binary file, and it follows a specific format described in the [original web site](http://yann.lecun.com/exdb/mnist/). To help you get started with this data, an example function to load this data is provided below. You do not have to understand how this function works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "umjX2RpCh2Ke"
   },
   "outputs": [],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "#' readMNIST() - Function to read MNIST images/labels\n",
    "#' @param filename - Path to the local binary file\n",
    "#' @return 1-d (label) or 3-d (images) arrays of MNIST data\n",
    "readMNIST = function(filename) {\n",
    "  con = gzfile(filename,\"rb\")\n",
    "  hdr = readBin(con, integer(), n=2, endian=\"big\") ## read one byte to figure out file type\n",
    "  if ( hdr[1] == 2051 ) {         ## 2051 is a magic number for image files\n",
    "    nxy = readBin(con, integer(), n=2, endian=\"big\")  \n",
    "    return ( array( readBin(con, integer(), signed=FALSE, size=1, n=hdr[2]*nxy[1]*nxy[2], endian=\"big\"), dim=c(nxy[1],nxy[2],hdr[2]) ) )\n",
    "  } else if ( hdr[1] == 2049 ) {  ## 2049 is a magic number for label files\n",
    "    return ( readBin(con, integer(), signed=FALSE, size=1, n=hdr[2], endian=\"big\") )\n",
    "  } else {\n",
    "    stop(paste0(\"Cannot recognize the magic number \", hdr[1]))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6XpADxxo_jF",
    "outputId": "7e9ed844-2760-48a6-9d53-6f415e9d3f2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]    28    28 60000\n",
      "[1] 60000\n"
     ]
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "train.X = readMNIST(trainXf)  ## read training images\n",
    "train.Y = readMNIST(trainYf)  ## read training labels\n",
    "print(dim(train.X))           ## print the dimension of training images (3-d array)\n",
    "print(length(train.Y))        ## print the dimension of training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coo2CQ7Fktj7",
    "outputId": "14845dea-4964-4666-b6a9-d7d32d43365e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]    28    28 10000\n",
      "[1] 10000\n"
     ]
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "test.X = readMNIST(testXf)  ## read test images\n",
    "test.Y = readMNIST(testYf)  ## read test labels\n",
    "print(dim(test.X))          ## print the dimension of test images\n",
    "print(length(test.Y))       ## print the dimension of test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "z77ZYG4mlUfi",
    "outputId": "b23dd1f0-aff3-41cc-f659-92c7a684a4ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [,1] [,2] [,3] [,4] [,5] [,6]\n",
      "[1,]    0    0    0  177  253   47\n",
      "[2,]    0    0    0   98  254   49\n",
      "[3,]    0    0    0   56  250  116\n",
      "[4,]    0    0    0    0  240  144\n",
      "[5,]    0    0    0    0  198  150\n",
      "[6,]    0    0    0    0  143  241\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAYAAAD958/bAAAEGWlDQ1BrQ0dDb2xvclNwYWNl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\nF3dOAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## quick sanity checking\n",
    "print(train.X[10:15,20:15,3]) ## print some part of the large 3-d array\n",
    "## draw first 25 images: note that the images are mirrored in columns\n",
    "par(mfrow=c(5,5))\n",
    "par(mar=c(0,0,0,0))\n",
    "for(i in 1:25) { image(train.X[,28:1,i],col=gray((0:255)/255)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "KoycYw1yoHj4",
    "outputId": "9382ffdd-8661-4749-b5a1-2926e5c6f9ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "   0.00    0.00    0.00   33.32    0.00  255.00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "train.Y\n",
       "   0    1    2    3    4    5    6    7    8    9 \n",
       "5923 6742 5958 6131 5842 5421 5918 6265 5851 5949 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "summary(train.X) ## show the summary of pixel-wise intensities\n",
    "table(train.Y)   ## show the distribution of each digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qs1gVWQ0qTp"
   },
   "source": [
    "## Task 1 : Binary classification of MNIST data\n",
    "\n",
    "The first task is to implement an algorithm that performs binary classification of MNIST images. \n",
    "1. Subset images/labels that contains only two labels (you may select a pair of digits: default is 0 and 1).\n",
    "2. Example code will show how to classify images with logistic Ridge regression using `glmnet()` package.\n",
    "3. You are required to implement logistic Ridge regression by using the L-BFGS-B algorithm implemented in `optim()` function.\n",
    "  * You need to comment your code well and write a brief documentation to explain how you implemented it.\n",
    "  * The instructors will review your code and may provide specific comments. \n",
    "4. You are encouraged to perform additional follow-ups. Examples include the following:\n",
    "  * (Easy) Try different pairs of labels to understand the data-dependent differences in the classification performance.\n",
    "  * (Medium) Use different objective functions (e.g. LASSO) or optimization methods (e.g. Nelder-Mead) and see how those methods perform in terms of accuracy and computational efficiency. \n",
    "  * (Hard) Try to implement multi-class classification algorithm from scratch. You may choose 3 or more (up to 10!) digits to classify simultaneously. Clearly describe what your objective function is and how you optimized it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUleqQaRtAE4"
   },
   "source": [
    "### Preparing input data for binary classification\n",
    "\n",
    "The function below help you reshape the original data into a format that is easy to apply a binary classification algorithm. You are expected to specify a pair of digits as positive and negative labels. The function `prep_binary_classification()` returns a list containing a matrix `X` and a vector `y` as attributes. The matrix `X` has 784 (=28 x28) columns, and the number of rows equivalent to the number of positive + negative labels. The vector `y` is encoded as either 1 (for positive label) or 0 (for negative label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "abD-BiQh0pna"
   },
   "outputs": [],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## prepare a model given a pair of digits\n",
    "#' @param images - (r * c * n) array containing n images\n",
    "#' @param labels - Size n vector of containing n labels\n",
    "#' @param posLabel - The label(s) considered as positive label \n",
    "#' @param negLabel - The label(s) considered as negative label\n",
    "#' @return A list containing then following attributes\n",
    "#'         * X - Matrix of (nrow=number of selected labels, ncol=r*c)\n",
    "#'         * y - Vector labels, encoded as zeros (negative) and ones (positive)\n",
    "prep_binary_classification = function(images, labels, posLabel = 1, negLabel = 0) {\n",
    "  dims = dim(images)\n",
    "  X.pos = t(matrix(images[,,labels %in% posLabel],nrow=dims[1]*dims[2])) ## 784 * n1 matrix\n",
    "  X.neg = t(matrix(images[,,labels %in% negLabel],nrow=dims[1]*dims[2])) ## 784 * n1 matrix\n",
    "  return(list(X=rbind(X.pos, X.neg),y = c(rep(1,nrow(X.pos)),rep(0,nrow(X.neg)))))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmaKaLvx4baT",
    "outputId": "eac0e571-0d37-4db6-d822-139c000c4e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 12665   784\n",
      "[1] 12665\n",
      "[1] 2115  784\n",
      "[1] 2115\n"
     ]
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL - IF YOU WANT TO CHANGE LABELS, USE TASK 1b.\n",
    "## Subsample training and test datasets\n",
    "trn = prep_binary_classification(train.X, train.Y, 1, 0)\n",
    "tst = prep_binary_classification(test.X, test.Y, 1, 0)\n",
    "## Check the dimensions of the data\n",
    "print(dim(trn$X))\n",
    "print(length(trn$y))\n",
    "print(dim(tst$X))\n",
    "print(length(tst$y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxzSZgequ87d"
   },
   "source": [
    "### Pre-task: Perform logistic Ridge regression using `glmnet`\n",
    "\n",
    "We will first use logistic ridge regression implemented in `glmnet` package to fit the data, to illustrate what a reasonable regression model is expected to behave. \n",
    "\n",
    "Let $\\boldsymbol{x}_i$ be a row of `X`, and $\\sigma(z) = \\frac{1}{1+e^{-z}}$. Briefly, logistic Ridge regression will attempt to maximum the following penalized likelihood function.\n",
    "\n",
    "$$\n",
    "\\log L(\\boldsymbol{\\beta},\\lambda) = \\frac{1}{n}\\sum_{i=1}^n \\left[y_i\\log\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right) + (1-y_i)\\log\\left(1-\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)\\right) \\right] - \\frac{\\lambda}{2n}\\|\\boldsymbol{\\beta}\\|_2^2\n",
    "$$\n",
    "\n",
    "which is equivalent to minimize $-\\log L(\\boldsymbol{\\beta},\\lambda)$. The `glmnet()` function provides an easy way to perform the Ridge regression as follows:\n",
    "\n",
    "In this exercise below, to save the computational time, we will <u>train the model using the ***test*** data</u> instead of the training data because test data is smaller in size. We will evaluate the model across all train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CP_xGnKnBdZT",
    "outputId": "6d6cc026-621e-44ae-991f-b7dfd2edb41e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression train took 0.31500 seconds\n"
     ]
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## Train the model\n",
    "tic <- proc.time()\n",
    "## alpha=0 : Ridge regression, lambda=1 is a regularization parameter\n",
    "## Note that we are training with test data to save computational time.\n",
    "ridge.fit <- glmnet(tst$X, tst$y, family=\"binomial\", alpha = 0, lambda = 1) \n",
    "toc <- proc.time()\n",
    "## Report the elapsed time\n",
    "cat(paste0(\"Ridge regression train took \",sprintf(\"%.5f\",(toc-tic)[3]),\" seconds\\n\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YBnkyxjykJZ"
   },
   "source": [
    "You can evaluate the accuracy of your classification results by comparing the predicted probability with the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlLPFU2EB-IE",
    "outputId": "77fddaa6-6570-434a-c5f2-04a6d4a9e9aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 4 x 4\n",
      "   true  pred     n     freq\n",
      "  <dbl> <int> <int>    <dbl>\n",
      "1     0     0  5885 0.465   \n",
      "2     0     1    38 0.00300 \n",
      "3     1     0    10 0.000790\n",
      "4     1     1  6732 0.532   \n"
     ]
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## Evaluate the prediction accuracy using train data (as test data was used for training)\n",
    "ridge.pred <- predict(ridge.fit, trn$X, type=\"response\") \n",
    "## Tabulate the TP/FP/TN/FN\n",
    "print(data.frame(pred=as.integer(ridge.pred > 0.5), true=trn$y) %>% count(true,pred) %>% mutate(freq=n/sum(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMF_GTK_C6Xy"
   },
   "source": [
    "### ***TASK 1a: IMPLEMENT LOGISTIC RIDGE REGRESSION ON YOUR OWN*** (required)\n",
    "\n",
    "The goal of the first project is to implement logistic regression on your own. Here is a basic guideline.\n",
    "* You need to implement `my.ridge.fit(X, y, lambda=1)` using only `base` and `stats` package.\n",
    "* The function should return a list, including at least the following two attributes:\n",
    "  * `par` : A vector of coefficients from logistic ridge regression with size `ncol(X)`\n",
    "  * `counts` : Evaluates how many times the objective functions and gradients are evaluated.\n",
    "  * Note that these attributes can be easily obtained from the output of `stats::optim()` function.  \n",
    "* Using `stats::optim()` function with `L-BFGS-B` algorithm is highly recommended.\n",
    "* Use $-\\log L(\\boldsymbol{\\beta},\\lambda)$ as the objective function and provide the gradient as needed.  \n",
    "\n",
    "* For this required task, you are not allowed to use external libraries beyond default R packages (e.g. `base`, `utils`, `stats`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vd0WGydp9G_X"
   },
   "source": [
    "#### <u>PART I - DESCRIPTION OF YOUR IMPLEMENTATION (WRITE ON YOUR OWN)</u>\n",
    "\n",
    "#### `my.ridge.fit()`\n",
    "\n",
    "1. The penalized log-likelihood function of logistic Ridge regression  \n",
    "\n",
    "Let $\\boldsymbol{x}_i$ be a row of `X`, and $\\sigma(z) = \\frac{1}{1+e^{-z}}$. Briefly,  will attempt to maximum the following penalized log-likelihood function.\n",
    "\n",
    "$$\n",
    "\\log L(\\boldsymbol{\\beta},\\lambda) = \\frac{1}{n}\\sum_{i=1}^n \\left[y_i\\log\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right) + (1-y_i)\\log\\left(1-\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)\\right) \\right] - \\frac{\\lambda}{2n}\\|\\boldsymbol{\\beta}\\|_2^2\n",
    "$$\n",
    "\n",
    "To maximize the likelihood function value is equivalent to minimize $-\\log L(\\boldsymbol{\\beta},\\lambda)$. \n",
    "\n",
    "\n",
    "2. Derive the gradient of the penalized log-likelihood function.   \n",
    "\n",
    "Based on the expression above,we can derive the gradient of log-likelihood function on $\\beta$ as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\log L(\\boldsymbol{\\beta},\\lambda)}{\\partial \\beta} = \\frac{1}{n}\\sum_{i=1}^n \\left[y_i \\frac{\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)'}{\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)} + (1-y_i)\\frac{-\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)'}{1-\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)}\\right] - \\frac{\\lambda}{n}\\boldsymbol{\\beta}\n",
    "$$\n",
    "Where $\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)'$= ${\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)}^2e^{-\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)}$=$\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)(1-\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right))$, which is the the gradient of $\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)$\n",
    "\n",
    "3. Description on my function:   \n",
    "\n",
    "The function `my.ridge.fit()` consists of three main parts:  \n",
    " - Contruct `fr()` function:  \n",
    " \n",
    " For this part, the log-likelihood function in part (1) is written and computed based on matrix operations in R. However, the return value of `fr()` is the negetive value of the log-likelihood function because `L-BFGS-B` algorithm is intended for minimization problems.  \n",
    " \n",
    " It's also worth noting that the clip value is applied on $\\boldsymbol{x}_i^T\\boldsymbol{\\beta}$ to prevent the occurence of *Inf* of $\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)$ when $\\boldsymbol{x}_i^T\\boldsymbol{\\beta}$ is negetive and has a relatively large absolute value.  \n",
    " \n",
    " In this case, values in $\\boldsymbol{x}_i^T\\boldsymbol{\\beta}$ that are smaller than -10 are all clipped to -10, which appears to work well in the data set without introducing notable bias to the estimate of `fr()`.  \n",
    " \n",
    " - Contruct `grr()` function:  \n",
    " \n",
    "  The gradient of log-likelihood function on $\\beta$ in part (2) is written and computed based on matrix operations in R. The return value of `grr()` is also the negetive value of the gradient of log-likelihood function.  \n",
    "  \n",
    " - Optimize target function using `stats::optim()` function with `L-BFGS-B` algorithm\n",
    " \n",
    " Using stats::optim() function with parameters (fr, grr, L-BFGS-B).  \n",
    " \n",
    "The return of `my.ridge.fit()` is a list containing the two attributes `par`and `counts`, which are the estimate of coefficients from logistic ridge regression and \n",
    " the number of function calls made on objective function and gradients. With `par`, predictions are attainable on new data of $ X $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRbQgxWe-e_K"
   },
   "source": [
    "#### <u>PART II - ACTUAL IMPLEMENTATION </u>\n",
    "\n",
    "_Fill in the code in the cell below. You may add additional cells if needed._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vxo6OwxL5W4X"
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## PLEASE MODIFY THIS CELL (or Add more cells if needed)\n",
    "##########################################################\n",
    "## TASK 1a: Implement my.ridge.fit() function that performs logistic regression\n",
    "#' @param X - (n x p) matrix of predictor variables. Assume that intercept term is already included in the input.\n",
    "#' @param y - A size n vector of zeros (negative) and ones (positives) as labels.\n",
    "#' @return A list containing at least the following two attributes, which can be passed from stats::optim()\n",
    "#'    * par - A size p vector of coefficients from logistic ridge regression.\n",
    "#'    * counts - The number of function calls made on objective function and gradients.\n",
    "#'    * You may include other attributes as you want.  \n",
    "\n",
    "# 1.deduction on fr and grr\n",
    "# 2. explosion => clip value\n",
    "# 3. starting point(beta) and clip values\n",
    "my.ridge.fit = function(X, y, lambda=1) {\n",
    "  ## IMPLEMENT YOUR OWN FUNCTION HERE:\n",
    "  ## * Note that you may have to deal with numerical precision challenges.\n",
    "  n <- dim(X)[1]\n",
    "  p <- dim(X)[2]\n",
    "  best_beta = rep(1,p)#\n",
    "  sigma <- function(x){1/(1 + exp(-x))}\n",
    "  sigma_p <- function(x){sigma(x)^2 * exp(-x)}\n",
    "    \n",
    "#  5th version     \n",
    "fr <- function(x) {   ## -log likelihood function\n",
    "    c_val = 10\n",
    "    Xx = X %*% x\n",
    "    Xx_clip = ifelse(Xx <= -c_val, - c_val, ifelse(Xx >= c_val, c_val, Xx))\n",
    "    mat_sigma = sum((y-1) * Xx) - sum(log(1 + exp(-Xx_clip)))\n",
    "    log_lh = mat_sigma/n - lambda*crossprod(x)/(2*n)\n",
    "    return(-log_lh)\n",
    "     }\n",
    "\n",
    "# 3rd version\n",
    "grr <- function(x) { ## Gradient of 'fr'\n",
    "     c_val = 10\n",
    "     Xx = X %*% x\n",
    "     Xx_clip = ifelse(Xx <= -c_val, - c_val, ifelse(Xx >= c_val, c_val, Xx))\n",
    "     mat_y = (y - sigma(Xx_clip)) # n*1\n",
    "     mat_sigma =  matrix(mat_y,1,n) %*% X\n",
    "     log_lh_g = (mat_sigma - lambda*x)/n # p*1\n",
    "     return(-log_lh_g)\n",
    "    }\n",
    "    \n",
    "  result = optim(best_beta, fr, grr, method = \"L-BFGS-B\")#\n",
    "  return(list(par=result$par, counts=result$counts)) ## Make sure to return a list\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKcIpeel85NT"
   },
   "source": [
    "### Evaluation of TASK 1a\n",
    "\n",
    "***DO NOT MODIFY the code fragment below.*** \n",
    "\n",
    "This code evaluates your output from your previous function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "QhtDn64yHWel",
    "outputId": "f1c94bd5-2bb4-4273-d29b-e949107df62e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New ridge regression train took 0.41600 seconds\n",
      "Number of (function, gradient) evaluations: (60,60)\n"
     ]
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "tic <- proc.time()\n",
    "rst <- my.ridge.fit(cbind(1,tst$X), tst$y, 1) ## run the new method\n",
    "toc <- proc.time()\n",
    "cat(paste0(\"New ridge regression train took \",sprintf(\"%.5f\",(toc-tic)[3]),\" seconds\\n\")) \n",
    "cat(paste0(\"Number of (function, gradient) evaluations: (\",rst$counts[1],\",\",rst$counts[2],\")\\n\")) \n",
    "## Example output is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GHIT3V68Ujmx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 4 x 4\n",
      "   true  pred     n     freq\n",
      "  <dbl> <int> <int>    <dbl>\n",
      "1     0     0  5912 0.467   \n",
      "2     0     1    11 0.000869\n",
      "3     1     0    40 0.00316 \n",
      "4     1     1  6702 0.529   \n"
     ]
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## Evaluate the prediction accuracy using train data (as test data was used for training)\n",
    "sigmoid <- function(x) 1/(1+exp(-x))\n",
    "my.pred <- sigmoid(cbind(1,trn$X) %*% rst$par) \n",
    "## Tabulate the TP/FP/TN/FN\n",
    "print(data.frame(pred=as.integer(my.pred > 0.5), true=trn$y) %>% count(true,pred) %>% mutate(freq=n/sum(n)))\n",
    "## Example output is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BF8EEGpGV-G"
   },
   "source": [
    "#### <u>PART III - INTERPRET EVALUATION RESULTS (WRITE ON YOUR OWN)</u>\n",
    "\n",
    "_Briefly describe the followings: (it does not have to be long. 1-2 sentences each is fine.)_\n",
    "* _Does your result make sense, in terms of speed and accuracy?_  \n",
    "\n",
    "  The result appears make good sense. The new ridge regression train took 0.414 seconds, and the accuracy reaches to approxiamtely 99.6%.  \n",
    "  \n",
    " \n",
    "* _What was the tricky part in your implementation? How did you address the challenges?_  \n",
    "\n",
    "   The tricky part is the occurence of *Inf* for  $\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)$ when $\\boldsymbol{x}_i^T\\boldsymbol{\\beta}$ is negetive and has a relatively large absolute value.\n",
    "   To solve this problem, I used the clip value technique on $\\boldsymbol{x}_i^T\\boldsymbol{\\beta}$. To be specific,  values in $\\boldsymbol{x}_i^T\\boldsymbol{\\beta}$ that are smaller than -10 are all clipped to -10. It appears that this clip helps a lot on the explosion of the value. \n",
    "  \n",
    " \n",
    "* _How could your implementation be potentially improved?_  \n",
    "  \n",
    "  I think there should be better ways to address the problem of the explosion of $\\sigma\\left(\\boldsymbol{x}_i^T\\boldsymbol{\\beta}\\right)$ when $\\sigma$ is very large. For the clip-value method, bias is introduced into the the estiamte of the likelihood function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlEAylVCKUUz"
   },
   "source": [
    "### ***TASK 1b: EXPLORE MORE ON MNIST CLASSIFICATION ON YOUR OWN*** (optional)\n",
    "\n",
    "This is an open-ended task. You are encouraged to perform additional follow-ups on classification. Examples include the following:\n",
    "  * (Easy) Try different pairs of labels to understand the data-dependent differences in the classification performance.\n",
    "  * (Medium) Use different objective functions (e.g. LASSO) or optimization methods (e.g. Nelder-Mead) and see how those methods perform in terms of accuracy and computational efficiency. \n",
    "  * (Hard) Try to implement multi-class classification algorithm from scratch. You may choose 3 or more (up to 10!) digits to classify simultaneously. Clearly describe what your objective function is and how you optimized it.\n",
    "\n",
    "Add additional code or text cells as needed below. Make sure to include your brief report on your work so that instructors can understand what you accomplished clearly.\n",
    "\n",
    "For this optional task, you are allowed to use any external libraries as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "H7BC5hPK3ZbI"
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## PLEASE MODIFY THIS CELL (or Add more cells if needed)\n",
    "## To perform TASK 1b (optional)\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIsxpVAzL1d-"
   },
   "source": [
    "## Task 2 : Clustering of MNIST data\n",
    "\n",
    "The second task is to implement an algorithm that performs multi-class clustering of MNIST images. \n",
    "1. Subset images/labels that contains 3 or more labels (to make the problem simple, but not too simple).\n",
    "2. You are required to implement at least one type of clustering method (e.g. E-M, k-means, Louvain).\n",
    "  * You need to comment your code well and write a brief documentation to explain how you implemented it.\n",
    "  * The instructors will review your code and may provide specific comments. \n",
    "3. You are also encouraged to implement additional methods and perform further experiments. Examples include the following:\n",
    "  * (Easy) Try different sets of labels to understand the data-dependent differences in the clustering performance. Also, try to evaluate the robustness of your algorithm based on different initial points.\n",
    "  * (Medium) Try to implement an algorithm that automatically select the optimal number of clusters depending on the data.\n",
    "  * (Hard) Try to implement another algorithm and compare the performance between the algorithms. Describe which ones are better in which cases and justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0DbzD5L4eTM"
   },
   "source": [
    "### Pre-task: Prepare the data for clustering\n",
    "\n",
    "This section select a subset of labels from the test data (we work on test data rather than training to reduce response time), and cluster the corresponding images without using the labels at all. In this example, three labels - 0, 1, 2 are selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tUb6mgwS0wCQ"
   },
   "outputs": [],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## prepare data given a set of digits\n",
    "#' @param images - (r * c * n) array containing n images\n",
    "#' @param labels - Size n vector of containing n labels\n",
    "#' @param selectedLabels - The label(s) considered for clustering  \n",
    "#' @return A list containing then following attributes\n",
    "#'         * X - Matrix of (nrow=number of selected labels, ncol=r*c)\n",
    "#'         * y - Vector selected labels\n",
    "prep_multiway_clustering = function(images, labels, selectedLabels) {\n",
    "  dims = dim(images)\n",
    "  idx = which(labels %in% selectedLabels)\n",
    "  X = t(matrix(images[,,idx],nrow=dims[1]*dims[2])) ## 784 * n matrix\n",
    "  return(list(X=X,y = labels[idx]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NcRhU3wY0x0H"
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "## Select 3 labels for clustering\n",
    "selectedLabels = c(0,1,2)\n",
    "tst = prep_multiway_clustering(test.X, test.Y, selectedLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5LiSZ5e5kkS"
   },
   "source": [
    "### ***TASK 2a: IMPLEMENT 3-CLASS CLUSTERING ON YOUR OWN*** (required)\n",
    "\n",
    "The goal of the first project is to implement 3-class clustering. Here is a basic guideline.\n",
    "* You need to implement `my.clustering(X, nclust, max.iter, tol)` using only `base` and `stats` package.\n",
    "* The function should return a list, including at least the following two attributes:\n",
    "  * `mu` : A `ncol(X) * nclust` matrix of mean pixel strength (0-1 scale)  for each cluster. \n",
    "  * `est` : The best guess cluster of each image to one of the labels (i.e. in `1:nclust`). Note that the cluster id and the images labels do not have direct correspondence and may be permuted in different runs.\n",
    "* For this required task, you are not allowed to use external libraries beyond default R packages (e.g. `base`, `utils`, `stats`). However, if you want to use algorithms based on nearest neighbors, you are allowed to use `RcppAnnoy` package. If you really have to import additional libraries, consult with your instructors beforehand.\n",
    "* If you do not know what to choose, implementing an E-M algorithm may be a safe option that the instructors can give useful inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>PART I - DESCRIPTION OF YOUR IMPLEMENTATION (WRITE ON YOUR OWN)</u>\n",
    "\n",
    "#### `my.clustering(X, nclust, max.iter=1000L, tol=1e-5)`\n",
    "\n",
    "1. Basic description on `my.clustering()`\n",
    "  My function `my.clustering()` is constructed primarily based on EM algorithm with a mixture of Bernoulli distribution.   \n",
    "  \n",
    "  The input includes `X`(the original n * 784 matrix of images), `nclust` (number of clusters to generate), `max.iter`(maximum number of iteration) and `tol`(tolerance to define convergence).  \n",
    "  \n",
    "  In the function body, firstly, the values in `X` are  binarized to 0-1, which corresponds to the Bernoulli distribution. Then EM algorithm is implemented on the the binary data with the pre-specified parameter `nclust` via `binMixEm()`,  which gives an output of a list containing all the useful results yieldes by the EM algorithm. Finally, the predictions for classification of each image(row) in the training set is computed using the output `prob_mat` from `binMixEm()`.\n",
    " \n",
    " \n",
    "2. Mathematical formulation of EM algorithm with a mixture of Multivariate Bernoulli distribution  \n",
    "\n",
    "    - Likelihood function \n",
    "        - Complete-data likelihood  \n",
    "    $L(\\theta) = p(\\boldsymbol{x},\\boldsymbol{z}|\\theta) \\\\\n",
    "    = \\prod_{i=1}^n \\pi_{z_i} P(\\boldsymbol{x_i}|\\boldsymbol{p}_{z_i}) \\\\\n",
    "    = \\prod_{c=1}^k  \\prod_{i=1}^n \\left\\{\\pi_{z_i} P(\\boldsymbol{x_i}|\\boldsymbol{p}_{z_i})\\right\\}^{I_{z_i=c}} \\\\\n",
    "    = \\prod_{c=1}^k \\prod_{i=1}^n  \\left\\{\\pi_{z_i} \\prod_{j=1}^{784} { P({x_{i,j}}|{p}_{{z_{i}},j})}\\right\\}^{I_{z_i=c}}\\\\\n",
    "    $\n",
    "    where:  \n",
    "    $\\boldsymbol{x}$ is a $n * 784$ binary matrix represents the data $X$.  \n",
    "    $\\boldsymbol{z}$ is a $n$ matrix represents the cluster number that each row in  $X$ belongs to.  \n",
    "    $\\boldsymbol{x_i}$ is a $1 * 784$ vector of independent random variables that follow Bernoulli distributions with different parameters.   \n",
    "    $\\boldsymbol{p}_{z_i}$ is thus also a $1 * 784$ vector corresponding to the parameters of each Bernoulli distribution in $\\boldsymbol{x_i}$.   \n",
    "    \n",
    "        - Log-likelihood  \n",
    "    $\\begin{aligned}\n",
    "    l(\\theta) &= log L(\\theta)\\\\\n",
    "    &= log p(\\boldsymbol{x},\\boldsymbol{z}|\\theta) \\\\\n",
    "    &= \\sum_{i=1}^n log(\\pi_{z_i}) + log(P(\\boldsymbol{x_i}|\\boldsymbol{p}_{z_i})) \\\\\n",
    "    &=  \\sum_{c=1}^k \\sum_{i=1}^n  {I_{z_i=c}} \\left\\{log\\pi_{z_i}+ log(P(\\boldsymbol{x_i}|\\boldsymbol{p}_{z_i}))\\right\\}\\\\\n",
    "    &= \\sum_{c=1}^k \\sum_{i=1}^n {I_{z_i=c}}\\left\\{ {log\\pi_{z_i}+ \\sum_{j=1}^{784}logP({x_{i,j}}|{p}_{{z_{i}},j})}\\right\\}\n",
    "    \\end{aligned}\n",
    "    $ \n",
    "    \n",
    "        - EM algorigthm   \n",
    "\n",
    "        - E-step : calculate the expectation of Log-likelihood based on current parameters\n",
    "       $\\begin{aligned}\n",
    "       Q(\\theta|\\theta^{(t)}) &= E_{z|x,\\theta ^{(t)}}[logP(\\boldsymbol{x},\\boldsymbol{z}|\\theta)]  \\\\\n",
    "       &= \n",
    "       \\sum_{c=1}^k \\sum_{i=1}^n P(z_i=c|x_i, p^{(t)}) \\left\\{ {log\\pi_{z_i}+log(P(\\boldsymbol{x_i}|\\boldsymbol{p}_{z_i}))} \\right\\} \\\\\n",
    "       &= \n",
    "       \\sum_{c=1}^k \\sum_{i=1}^n P(z_i=c|x_i, p^{(t)}) \\left\\{ {log\\pi_{z_i}+\\sum_{j=1}^{784} logP({x_{i,j}}|{p}_{{z_{i}},j})} \\right\\} \n",
    "       \\end{aligned}\n",
    "       $\n",
    "    \n",
    "     where $ P({x_{i,j}}|{p}_{{z_{i}},j})= {p}_{{z_{i}},j}^{x_{i,j}}(1-{p}_{{z_{i}},j})^{1-x_{i,j}}$ according to Bernoulli distribution.\n",
    "    \n",
    "     Based on Bayes' theorem, the classification probabilities(prob_mat) for 'class assignment' in this case is :\n",
    "    \n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    P(z_{i}=c|x_i,\\pi,p) &=\\frac{P(z_{i}=c,x_i,\\pi,p)}{P(x_i,\\pi,p)} \\\\\n",
    "    &= \\frac{\\pi_cP(\\boldsymbol{x_{i}}|\\boldsymbol{{p}_{c}})}{\\sum_{c=1}^k \\pi_cP(\\boldsymbol{x_{i}}|\\boldsymbol{{p}_c})} \\\\\n",
    "    &= \\frac{\\pi_c\\prod_{j=1}^{784}P({x_{i,j}}|{p}_{c,j})}{\\sum_{c=1}^k \\pi_c\\prod_{j=1}^{784}P({x_{i,j}}|{p}_{c,j})}\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "    \n",
    "        - M-step : Update the parameters to maximize the likelihood function in E-step  \n",
    "             \n",
    "          In the M-step, we try to maximize the loglikelihood $Q(\\theta|\\theta^{(t)})$ w.r.t parameters $\\boldsymbol{p}$ and $\\boldsymbol{\\pi}$, which can be realized by taking the derivatives of $\\boldsymbol{p}$ and $\\boldsymbol{\\pi}$ and set them to zeros.\n",
    "             \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Update $\\pi_{c}$ \n",
    "\n",
    "\n",
    "To get $\\pi_{c}$, we first construct a Lagrange function beacause of the constraint:\n",
    "$\\sum_{c=1}^k \\pi_c=1$.\n",
    "                \n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\boldsymbol{\\pi},\\lambda) \n",
    "&= Q(\\theta|\\theta^{(t)})+ \n",
    "\\lambda \\left\\{ \\sum_{i=1}^n \\pi_i-1\\right\\}     \n",
    "\\end{aligned}\n",
    "$$\n",
    "Then set the derivative wrt $\\pi_{c}$ and $\\lambda$ in $L(\\boldsymbol{\\pi},\\lambda)$ to zero, we can get: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{L(\\boldsymbol{\\pi},\\lambda)}{\\partial \\pi_{c}}\n",
    "&= \\frac{\\sum_{i=1}^{n} P(z_{i}=c|x_i,\\pi^{(t)},p^{(t)})}\n",
    "{\\pi_{c}} + \\lambda = 0  \n",
    "\\rightarrow \n",
    "\\pi_{c} = \\frac{-\\lambda}{\\sum_{i=1}^{n} P(z_{i}=c|x_i,\\pi^{(t)},p^{(t)})}\n",
    "\\\\\n",
    "\\sum_{c=1}^k \\pi_c &= 1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Given that $\\sum_{i=1}^{n} \\sum_{c=1}^{k}P(z_{i}=c|x_i,\\pi^{(t)},p^{(t)})=n$, we have:   \n",
    "$$\n",
    "\\begin{aligned} \n",
    "\\pi_{c}^{(t+1)} = \\frac{\\sum_{i=1}^n P(z_{i}=c|x_i,\\pi^{(t)},p^{(t)})}{n}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "             \n",
    "- Update $p_{c}$  \n",
    "    *Take the derivative w.r.t $\\boldsymbol{p_c}$*\n",
    "             \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial Q(\\theta|\\theta^{(t)}) }{\\partial \\boldsymbol{p}} \n",
    "             &= \\frac{\\sum_{c=1}^k \\sum_{i=1}^n P(z_i=c|x_i, p^{(t)}) \\left\\{ {log\\pi_{z_i}+log(P(\\boldsymbol{x_i}|\\boldsymbol{p}_{c}))} \\right\\}}{\\partial \\boldsymbol{p}} \\\\   \n",
    "             &=\\frac{\\sum_{c=1}^k \\sum_{i=1}^n  P(z_i=c|x_i, p^{(t)}) \\left\\{ \n",
    "             {log\\pi_{z_i}\n",
    "             +\\boldsymbol{x_i}^T log(\\boldsymbol{p}_{c})\n",
    "             +{1-\\boldsymbol{x_i}}^T log(1-\\boldsymbol{p}_{c}) \n",
    "             }\n",
    "             \\right\\}}{\\partial \\boldsymbol{p}} \\\\\n",
    "             &= \\sum_{i=1}^n P(z_i=c|x_i, p^{(t)}) \\left\\{ \\frac{\\boldsymbol{x_i}}{\\boldsymbol{p}_{c}} \n",
    "             + \\frac{\\boldsymbol{1-x_i}}{\\boldsymbol{1-p_{c}}} \n",
    "             \\right\\}\\\\\n",
    "             &= \\frac{\\sum_{i=1}^n P(z_i=c|x_i, p^{(t)})\n",
    "             (\\boldsymbol{x_i-p_c})}\n",
    "             {(\\boldsymbol{p}_{c}) * (\\boldsymbol{1-p_{c}})}\n",
    "             \\end{aligned}\n",
    "             $$\n",
    "             \n",
    "where * represents element-wise multiplication between two vectors.\n",
    "             \n",
    "Set the numerator in the equation above to zero, we have:  \n",
    "$$\n",
    "             \\begin{aligned}\n",
    "             p_{c}^{(t+1)} &= \\frac{\n",
    "             \\sum_{i=1}^n x_i P(z_{i}=c|x_i,\\pi^{(t)},p^{(t)})\n",
    "             }\n",
    "             {\\sum_{i=1}^n P(z_{i}=c|x_i,\\pi^{(t)},p^{(t)})\n",
    "             }\\\\\n",
    "             &= \\frac{\\sum_{i=1}^n x_iP(z_{i}=c|x_i,\\pi^{(t)},p^{(t)})}\n",
    "             {n\\pi_c^{(t+1)}}\n",
    "             \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementation of EM algorithm in ` my.clustering()`\n",
    "  -  Class `binMixEm`\n",
    "      - Parameter initialization\n",
    "          - `pi_vec`: Randomly initialized and normalized with k numbers from uniform distruibution between 0 and 1\n",
    "          - `mu_vec`: Initialized by the k equal-spaced quantiles from each column of the data.\n",
    "      - Iterative procedure  \n",
    "        Each interation consists of 4 main steps:  \n",
    "        1. Update the classification probabilities and likelihood with latest parameters with the formulas in E-step above.  \n",
    "        2. Update the class proportion `pi_vec` with the formula in M-step above.  \n",
    "        3. Update the k*784 Bermoulli distribution parameters `p_mat` with the formula in M-step above.  \n",
    "        4. Check convergence conditions.  \n",
    "        \n",
    "      - Expected results\n",
    "        Given that EM algorithm always increases the log-likelihood in each iteration, the algorithm is expected to converge in a relatively small number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DngiJfgl89jl"
   },
   "source": [
    "#### <u>PART II - ACTUAL IMPLEMENTATION </u>\n",
    "\n",
    "_Fill in the code below. You may add additional cells if needed._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "g7pmyJbl00vm"
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## PLEASE MODIFY THIS CELL (or Add more cells if needed)\n",
    "##########################################################\n",
    "## Implement your own clustering algorithm\n",
    "#' @param X : (n * 784) matrix of images (you may consider binarizing the matrix at X[i,j] == 128 if needed)\n",
    "#' @param nclust : Number of clusters to generate\n",
    "#' @param max.iter : Maximum number of iteration, may end early based on convergence criteria\n",
    "#' @param tol : Parameters for determining convergence.\n",
    "#' @return A list containing at least the following attributes:\n",
    "#'    * mus - A [ ncol(X) * nclust ] matrix of mean pixel strength (0-1 scale)  for each cluster.\n",
    "#'    * est - The best guess cluster of each image to one of the labels (i.e. in `1:nclust`). \n",
    "\n",
    "my.clustering = function(X, nclust, max.iter=1000L, tol=1e-5) {\n",
    "    # binarizing the matrix at X[i,j] == 128   \n",
    "    bin_X = ifelse(X>=128,1,0)\n",
    "    # use EM algorithm to make predictions\n",
    "    EM <- binMixEm$new(input_dat = bin_X, num_components = nclust)\n",
    "    res_EM <- EM$run.EM(loglik_tol=tol,max_iter=max.iter)\n",
    "#     plot(1:res_EM$iter, res_EM$loglik_list, type=\"l\")\n",
    "    # pi_vec # k*1    p_mat # k*784     bin_X# n * 784\n",
    "    est <- apply(res_EM$prob_mat, 1, which.max)\n",
    "    est <- sapply(est, function(x) c(1,2,0)[x])\n",
    "    return(list(mus=t(res_EM$p_mat), est=est))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' Create a class binMixEM\n",
    "binMixEm <- setRefClass(\"binMixEM\",\n",
    "                         fields=list(k = \"integer\",\n",
    "                                     n = \"integer\",\n",
    "                                     dat_mat = \"matrix\", # n*784\n",
    "                                     pi_vec = \"vector\", # k*1\n",
    "                                     p_mat = \"matrix\", # k*784 ;Bernouli(p)\n",
    "                                     prob_mat = \"matrix\", # n*k\n",
    "                                     loglik = \"numeric\",\n",
    "                                     tol = \"numeric\")\n",
    "                       )\n",
    "#' method to initialize binMixEm class (called with binMixEm$new)\n",
    "#' @param input_data - data to initalize\n",
    "#' @param num_components - number of components (k=3)\n",
    "binMixEm$methods(initialize = function(input_dat,num_components){\n",
    "  dat_mat <<- input_dat ## Use <<- to assign fields\n",
    "  k <<- num_components # k=3\n",
    "  n <<- length(dat_mat)\n",
    "})\n",
    "\n",
    "\n",
    "#' method to initialize parameters for E-M\n",
    "binMixEm$methods(init.paras = function(){\n",
    "    # pi_vec: k * 1\n",
    "    # dat_mat: n * 784 \n",
    "    # p_mat: k * 784\n",
    "    # prob_mat: n * k\n",
    "  tol <<- 1e-100  ## small number to avoid log(zero)  \n",
    "  set.seed(1234)\n",
    "  pi_vec <<- runif(3)\n",
    "  pi_vec <<- pi_vec/sum(pi_vec)\n",
    "#   pi_vec <<- rep(1.0/k,length=k)  ## uniform across components\n",
    "  ## pick means from equal-spaced quantiles from the data\n",
    "  ################################## sensitive!!\n",
    "  p_mat <<- apply(dat_mat,2,function(x) quantile(x,prob=seq(1/(2*k),1-1/(2*k),length=k)                                                ))\n",
    "  prob_mat <<- matrix(NA,nrow=n,ncol=k)              \n",
    "  loglik <<- -Inf\n",
    "})\n",
    "    \n",
    "    \n",
    "# Check carefully!\n",
    "#' E-step for E-M algorithm\n",
    "  binMixEm$methods(update.prob = function(){\n",
    "    ## prob_mat contains log-likelihood of each components\n",
    "      ################################ ? p_mat = 0 =>+tol to avoid dat_mat=0 => -Inf\n",
    "      # prob_mat:  n*k\n",
    "    prob_mat <<- t(log(pi_vec+tol)+ tcrossprod(log(p_mat+tol), dat_mat) + tcrossprod(log(1-p_mat+tol), 1 - dat_mat))\n",
    "    max_log_prob <- apply(prob_mat,1,max) ## local change, do not change the field value\n",
    "    prob_mat <<- exp(prob_mat - max_log_prob) ## re-scale probability (important)\n",
    "    sum_prob <- apply(prob_mat,1,sum)  ## sum probabilities for each observation      \n",
    "    prob_mat <<- prob_mat/sum_prob      ## normalize the probability E[z|theta]  \n",
    "    loglik <<- sum(max_log_prob + log(sum_prob))  ## evaluate log-likelihood\n",
    "  })\n",
    "\n",
    "    \n",
    "#' M-step for E-M algorithm to update pi_vec\n",
    "binMixEm$methods(update.pi = function(){\n",
    "  pi_vec <<- apply(prob_mat,2,mean) #k*1\n",
    "})\n",
    "\n",
    "#' M-step for E-M algorithm to update mu_vec\n",
    "binMixEm$methods(update.p = function(){ \n",
    "    # cheack dim(p_mat) = k * 784\n",
    "#   p_mat <<- (crossprod(prob_mat,dat_mat)/ n)/(pi_vec+tol) \n",
    "    p_mat <<- (crossprod(prob_mat,dat_mat)/ apply(prob_mat,2,sum))\n",
    "})\n",
    "\n",
    "                 \n",
    "#' check convergence of mixture binomial EM\n",
    "binMixEm$methods(check.tol = function(fmax,fmin,ftol){\n",
    "  delta = abs(fmax - fmin)\n",
    "  accuracy = (abs(fmax) + abs(fmin))*ftol\n",
    "  return(delta < (accuracy + tol))\n",
    "})  \n",
    "    \n",
    "#' main function for E-M algorithm\n",
    "binMixEm$methods(run.EM = function(max_iter=1000L,loglik_tol=1e-5){\n",
    "  convergence = 1L\n",
    "  init.paras()  ## initialize parameter\n",
    "  loglik_list = NULL\n",
    "  for(iter in 1:max_iter){\n",
    "#     print(iter)\n",
    "    loglik0 <- loglik ## log-likelihood of previous steps\n",
    "    update.prob() # E-step\n",
    "    update.pi()   # M-step for pi_vec\n",
    "    update.p()   # M-step for p_mat\n",
    "    loglik_list = c(loglik_list,loglik) # append log-likelihood\n",
    "    if(check.tol(loglik0,loglik,loglik_tol)){\n",
    "      convergence = 0 # converged\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "  return(list(convergence=convergence,p_mat=p_mat,\n",
    "              pi_vec=pi_vec,iter=iter,loglik_list=loglik_list,\n",
    "              prob_mat=prob_mat))\n",
    "  })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhaGu1zt9Hig"
   },
   "source": [
    "### Evaluation of TASK 2a\n",
    "\n",
    "<u>***DO NOT MODIFY The code fragment below.***</u> \n",
    "\n",
    "This code evaluates your output from your previous function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "ZiF6wjGT1Wrw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.097 sec elapsed\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in value[[3L]](cond): invalid graphics state\n",
     "output_type": "error",
     "traceback": [
      "Error in value[[3L]](cond): invalid graphics state\nTraceback:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## Run the clustering algorithm from the selected Data\n",
    "tic()\n",
    "rst = my.clustering(tst$X,length(selectedLabels))\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "q3MXRhHS1Yej"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAB4CAYAAAAqliEPAAAEGWlDQ1BrQ0dDb2xvclNwYWNl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\nQYABeDzaCS8hAAEIQGDCCPwf5g3c3cfQnA4AAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## Visualize rst$mus as images.\n",
    "options(repr.plot.width=4, repr.plot.height=1)\n",
    "par(mfrow=c(1,3))\n",
    "par(mar=c(0,0,0,0))\n",
    "apply(rst$mus,2,function(x) { image(matrix(x,28,28)[,28:1]*255,col=gray((0:255)/255)) })\n",
    "## below is a result from a working example with an E-M algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "hEEnh-dH1dkY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 8 x 4\n",
      "   true   est     n    freq\n",
      "  <int> <dbl> <int>   <dbl>\n",
      "1     0     0   951 0.302  \n",
      "2     0     1     8 0.00254\n",
      "3     0     2    21 0.00667\n",
      "4     1     1  1063 0.338  \n",
      "5     1     2    72 0.0229 \n",
      "6     2     0    38 0.0121 \n",
      "7     2     1    25 0.00794\n",
      "8     2     2   969 0.308  \n"
     ]
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CELL\n",
    "## Tabulate the contingency tables to understand the accuracy \n",
    "print(data.frame(est=rst$est, true=tst$y) %>% count(true,est) %>% mutate(freq=n/sum(n)))\n",
    "## below is a result from a working example with an E-M algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1qNUBJk9CjX"
   },
   "source": [
    "#### <u>PART III - INTERPRET EVALUATION RESULTS (WRITE ON YOUR OWN)</u>\n",
    "\n",
    "<u>***Please delete the text in this cell and fill in with your own.***</u>\n",
    "\n",
    "_Briefly describe the followings: (it does not have to be long. 1-2 sentences each is fine._\n",
    "* _Does your result make sense, in terms of speed and accuracy?_  \n",
    "\n",
    "  The result appears make sense, which can be directly visualized by the image above. It usually takes less than 2 seconds to converge in the algorithm above, and the accuracy over the three group is approxiamtely 94%.  \n",
    "  \n",
    " \n",
    "* _What was the tricky part in your implementation? How did you address the challenges?_  \n",
    "\n",
    "   The tricky part is the calculation of log-likehood in `update.prob()`. In the case of Bernoulli distribution, the log of $ P({x_{i,j}}|{p}_{{z_{i}},j})= {p}_{{z_{i}},j}^{x_{i,j}}(1-{p}_{{z_{i}},j})^{1-x_{i,j}}$ could be -Inf when the parameter ${p}_{{z_{i}},j}$ equals 1 or 0. To address this problem, I add a tolerance term `tol=1e-100` so that $log({p}_{{z_{i}},j}+tol)$ would be a finite negative number instead of -Inf, which helps to settle the problem well.\n",
    "  \n",
    " \n",
    "* _How could your implementation be potentially improved?_  \n",
    "  \n",
    "  I believe that the accuracy of classification can be further improved. \n",
    "  In the case of the classification of data with labels (0,1,2), the inaccuracy is introduced by the confusion between '1' and '2'. This can be a start point for further improvements focusing on distinguish them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikB5NMUs9pd8"
   },
   "source": [
    "### ***TASK 2b: EXPLORE MORE ON MNIST CLUSTERING ON YOUR OWN*** (optional)\n",
    "\n",
    "This is an open-ended task. You are encouraged to perform additional follow-ups on clustering. Examples include the following:\n",
    "  * (Easy) Try different sets of labels to understand the data-dependent differences in the clustering performance. Also, try to evaluate the robustness of your algorithm based on different initial points.\n",
    "  * (Medium) Try to implement an algorithm that automatically select the optimal number of clusters depending on the data.\n",
    "  * (Hard) Try to implement another algorithm and compare the performance between the algorithms. Describe which ones are better in which cases and justify your answer.\n",
    "\n",
    "Add additional code or text cells as needed below. Make sure to include your brief report on your work so that instructors can understand what you accomplished clearly.\n",
    "\n",
    "For this optional task, you are allowed to use any external libraries as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qn6v2ifi9scT"
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## PLEASE MODIFY THIS CELL (or Add more cells if needed)\n",
    "## To perform TASK 2b (optional)\n",
    "##########################################################"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Kailin Wang_BIOSTAT615 Midterm Project - Fall 2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
